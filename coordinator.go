package commit

import (
	"cs351/labrpc"
	"log"
	"sync"
	"sync/atomic"
	"time"
)

// Responses to the client
type ResponseMsg struct {
	tid        int
	committed  bool
	readValues map[string]interface{}
}

type Coordinator struct {
	servers       []*labrpc.ClientEnd
	respChan      chan ResponseMsg
	dead          int32
	mu            sync.Mutex                // shared state protection
	transactions  map[int]*TransactionState // map tid to current state
	respondedTids map[int]bool              // field to track responded tids
	relevant      map[int][]int             // field to track relevant servers for computation

}

// Start the 3PC protocol for a particular transaction
// TID is a unique transaction ID generated by the client
// This may be called concurrently
func (co *Coordinator) FinishTransaction(tid int) {

	co.mu.Lock()
	if _, ok := co.relevant[tid]; !ok {
		co.relevant[tid] = []int{}
	}
	co.mu.Unlock()

	// internal structure to hold each individual servers response during the prepare phase
	type prepareResult struct {
		serverID int           // Index of the server we accessed
		reply    *PrepareReply // server response
		ok       bool          // was the rpc call successful or not
	}

	var resultsMu sync.Mutex                           // wrap to protect the results array, typical concurrency pattern we have been doing
	var wg sync.WaitGroup                              // same as above pattern
	results := make([]*prepareResult, len(co.servers)) // response repo in a way

	// send rpcs to the servers
	for i := range co.servers {
		wg.Add(1)
		go func(serverID int) {
			defer wg.Done()

			// create the rpc calls and have a reply struct ready to injest
			args := &RPCArgs{Tid: tid}
			reply := &PrepareReply{}

			// send the prepare rpc
			ok := co.sendPrepare(serverID, args, reply)

			// record the result
			resultsMu.Lock()
			results[serverID] = &prepareResult{
				serverID: serverID,
				reply:    reply,
				ok:       ok,
			}
			resultsMu.Unlock()
		}(i)
	}
	wg.Wait()

	// review the responses
	relevantServers := []int{} // servers that logged ops for this TID
	votedYes := true

	for _, res := range results {
		// any issues like nil responses or failures
		if res == nil || !res.ok {
			votedYes = false
			break
		}

		if res.reply.Relevant {
			if !res.reply.VoteYes {
				votedYes = false
				break
			}
			relevantServers = append(relevantServers, res.serverID)
		} else {
			// irrelevant servers that vote yes should be ignored for the next phases
			continue
		}
	}

	// save the relevant servers for recovery in case of crash
	co.mu.Lock()
	co.relevant[tid] = relevantServers
	co.mu.Unlock()

	// again if the vote was no or no response send the abort RPCs and terminate
	if !votedYes {
		var wgAbort sync.WaitGroup
		for sid := range co.servers {
			wgAbort.Add(1)
			go func(serverID int) {
				defer wgAbort.Done()
				co.retrySendAbort(serverID, tid)
			}(sid)
		}
		wgAbort.Wait()

		// tell the client that this transaction was aborted
		co.respondOnce(ResponseMsg{tid: tid, committed: false})

		return
	}

	// if above is maintained till this point we can pre-commit
	var wgPreCommit sync.WaitGroup
	var preMu sync.Mutex
	preCommitFailed := false

	for _, serverID := range relevantServers {
		wgPreCommit.Add(1)
		go func(sid int) {
			defer wgPreCommit.Done()
			args := &RPCArgs{Tid: tid}

			timeout := time.After(300 * time.Millisecond)
			ticker := time.NewTicker(50 * time.Millisecond)
			defer ticker.Stop()

			for {
				select {
				case <-timeout:
					preMu.Lock()
					preCommitFailed = true
					preMu.Unlock()
					return
				case <-ticker.C:
					if co.killed() {
						preMu.Lock()
						preCommitFailed = true
						preMu.Unlock()
						return
					}
					if co.sendPreCommit(sid, args) {
						return
					}
				}
			}

		}(serverID)
	}
	wgPreCommit.Wait()

	// if any PreCommit failed in our case disconnect, abort the txn
	preMu.Lock()
	shouldAbort := preCommitFailed
	preMu.Unlock()

	if shouldAbort {
		var wgAbort sync.WaitGroup
		for sid := range co.servers {
			wgAbort.Add(1)
			go func(serverID int) {
				defer wgAbort.Done()
				co.retrySendAbort(serverID, tid)
			}(sid)
		}
		wgAbort.Wait()

		co.respondOnce(ResponseMsg{tid: tid, committed: false})
		return
	}

	// commit phase now
	readResults := make(map[string]interface{})
	var commitMu sync.Mutex

	ackCh := make(chan int, len(relevantServers)) // buffer no block on send
	acked := make(map[int]bool)

	for _, sid := range relevantServers {
		go co.retrySendCommit(sid, tid, readResults, &commitMu, ackCh)
	}

	// wait for all relevant servers to acknowledge commit
	timeout := time.After(10 * time.Second) // safety timeout (optional, you can remove it later)

	for len(acked) < len(relevantServers) {
		select {
		case sid := <-ackCh:
			if !acked[sid] {
				acked[sid] = true
			}
		case <-timeout:
			log.Fatalf("[Commit Phase] Timeout waiting for all commit ACKs for tid=%v", tid)
		}
	}

	// finally respond to the client
	co.respondOnce(ResponseMsg{tid: tid, committed: true, readValues: readResults})

}

// helper methods for re-tries
// retry sending the abort message, but stop after timeout
func (co *Coordinator) retrySendAbort(serverID int, tid int) {
	timeout := time.After(300 * time.Millisecond)   // sort of arbitrary time (give up time)
	ticker := time.NewTicker(50 * time.Millisecond) // retry every 50ms
	defer ticker.Stop()

	for {
		select {
		case <-timeout: // give up
			return
		case <-ticker.C: // try to send abort
			if co.killed() {
				return
			}
			if co.sendAbort(serverID, &RPCArgs{Tid: tid}) {
				return // on success break
			}
		}
	}
}

func (co *Coordinator) retrySendCommit(serverID int, tid int, readResults map[string]interface{}, mu *sync.Mutex, ackCh chan int) {
	args := &RPCArgs{Tid: tid}
	reply := &CommitReply{}

	for {
		if co.killed() {
			return
		}
		if co.sendCommit(serverID, args, reply) {
			// only merge after a successful commit
			mu.Lock()
			for k, v := range reply.GetResults {
				// only insert non nil values into the readResults weird stuff happening with the test
				if v != nil {
					readResults[k] = v
				}
			}
			mu.Unlock()

			ackCh <- serverID // signal that the server succeeded
			return
		}
		time.Sleep(50 * time.Millisecond) // retry logic every 50ms
	}
}

// helpers for recover state
// recoverCommit retries Commit RPCs to all relevant servers, then exits.
func (co *Coordinator) recoverCommit(tid int) {
	readResults := make(map[string]interface{})
	var mu sync.Mutex
	relevant := co.relevant[tid]
	if len(relevant) == 0 {
		// Fallback: if we didn't save relevant before crash, ask all servers
		relevant = []int{}
		for sid := range co.servers {
			reply := &QueryReply{}
			if co.sendQuery(sid, reply) {
				if state, ok := reply.Transactions[tid]; ok && state != stateOperations {
					relevant = append(relevant, sid)
				}
			}
		}
	}

	ackCh := make(chan int, len(relevant))
	acked := make(map[int]bool)

	for _, sid := range relevant {
		go co.retrySendCommit(sid, tid, readResults, &mu, ackCh)
	}

	// Wait for all relevant servers to ACK
	for len(acked) < len(relevant) {
		sid := <-ackCh
		acked[sid] = true
	}

	co.respondOnce(ResponseMsg{tid: tid, committed: true, readValues: readResults})
}

// commit phase retry logic to start
func (co *Coordinator) recoverPreCommitted(tid int) {
	// call recovercommit
	co.recoverCommit(tid)
}

// determineRecoveryPhase analyzes all server-reported states for a transaction
// and decides the most appropriate phase to resume from
func (co *Coordinator) determineRecoveryPhase(states []TransactionState) TransactionState {
	final := stateOperations // lowest possible state

	for _, s := range states {
		// abort txn on conditions below
		if s == stateAborted || s == stateVotedNo {
			return stateAborted
		}

		// commited resume it
		if s == stateCommitted {
			return stateCommitted
		}

		if s == statePreCommitted && final < statePreCommitted {
			final = statePreCommitted
		}
		if s == stateVotedYes && final < stateVotedYes {
			final = stateVotedYes
		}
	}

	// resume based on above comps
	return final
}
func (co *Coordinator) respondOnce(msg ResponseMsg) {
	co.mu.Lock()
	if co.respondedTids[msg.tid] {
		co.mu.Unlock()
		return
	}
	co.respondedTids[msg.tid] = true
	co.mu.Unlock()

	co.respChan <- msg
}

// Initialize new Coordinator
//
// This will be called at the beginning of a test to create a new Coordinator
// It will also be called when the Coordinator restarts, so you'll need to trigger recovery here
// respChan is how you'll send messages to the client to notify it of committed or aborted transactions
func MakeCoordinator(servers []*labrpc.ClientEnd, respChan chan ResponseMsg) *Coordinator {
	co := &Coordinator{
		servers:       servers,
		respChan:      respChan,                        // Initialize other fields here
		transactions:  make(map[int]*TransactionState), // initialize the TID state map
		respondedTids: make(map[int]bool),              // initalize reponded map
		relevant:      make(map[int][]int),             //  initialize relevant mapping

	}
	go co.recoverStateBlocking() // revert back to blocking

	return co
}

// new recover state that is actually the blocking version, we must block on recovery
func (co *Coordinator) recoverStateBlocking() {
	txnStates := make(map[int][]TransactionState)
	seenTids := make(map[int]bool)

	// query all servers for their known transaction states
	for sid := range co.servers {
		reply := &QueryReply{}
		for {
			if co.sendQuery(sid, reply) {
				break
			}
			time.Sleep(50 * time.Millisecond)
		}
		for tid, state := range reply.Transactions {
			txnStates[tid] = append(txnStates[tid], state)

			if state == stateCommitted || state == stateAborted {
				co.mu.Lock()
				co.respondedTids[tid] = true // mark as already responded
				co.mu.Unlock()
			}
		}
	}

	// determine relevant servers for each tid before the recovery
	for tid := range txnStates {
		relevant := []int{}
		for sid := range co.servers {
			reply := &QueryReply{}
			if co.sendQuery(sid, reply) {
				if state, ok := reply.Transactions[tid]; ok && state != stateOperations {
					relevant = append(relevant, sid)
				}
			}
		}
		co.mu.Lock()
		co.relevant[tid] = relevant
		co.mu.Unlock()
	}

	// resume whatever transactions
	for tid, states := range txnStates {
		if seenTids[tid] {
			continue // skip if they were processed
		}
		seenTids[tid] = true

		// rank phases get the highest safe one we can resume from
		phase := co.determineRecoveryPhase(states)
		switch phase {
		// different phases and the correct options for responses in a way
		case stateAborted, stateVotedNo:
			for sid := range co.servers {
				go co.retrySendAbort(sid, tid)
			}
		case stateCommitted:
			go co.recoverCommit(tid)
		case statePreCommitted:
			go co.recoverPreCommitted(tid)
		case stateVotedYes:
			go co.FinishTransaction(tid)
		default: // required
		}
	}
}

func (co *Coordinator) sendPrepare(server int, args *RPCArgs, reply *PrepareReply) bool {
	return co.servers[server].Call("Server.Prepare", args, reply)
}

func (co *Coordinator) sendAbort(server int, args *RPCArgs) bool {
	reply := struct{}{}
	return co.servers[server].Call("Server.Abort", args, &reply)
}

func (co *Coordinator) sendQuery(server int, reply *QueryReply) bool {
	return co.servers[server].Call("Server.Query", struct{}{}, reply)
}

func (co *Coordinator) sendPreCommit(server int, args *RPCArgs) bool {
	reply := struct{}{}
	return co.servers[server].Call("Server.PreCommit", args, &reply)
}

func (co *Coordinator) sendCommit(server int, args *RPCArgs, reply *CommitReply) bool {
	return co.servers[server].Call("Server.Commit", args, reply)
}

// The tester doesn't halt goroutines created by the Coordinator after each test,
// but it does call the Kill() method. Your code can use killed() to
// check whether Kill() has been called. The use of atomic avoids the
// need for a lock.
//
// The issue is that long-running goroutines use memory and may chew
// up CPU time, perhaps causing later tests to fail and generating
// confusing debug output. Any goroutine with a long-running loop
// should call killed() to check whether it should stop.
func (co *Coordinator) Kill() {
	atomic.StoreInt32(&co.dead, 1)
}

func (co *Coordinator) killed() bool {
	z := atomic.LoadInt32(&co.dead)
	return z == 1
}
